---

kubeProxyReplacement: true
k8sServiceHost: cp-address-automatic-replace
k8sServicePort: 6443

logOptions:
  format: json

resources:
# Cilium memory includes BPF data,
# its size depends on the number on pods on the node.
# Memory requirements range from 200Mi on small nodes to 1Gi+ on big nodes.
# Cilium recommends to run cilium without memory limit
# https://docs.cilium.io/en/stable/operations/performance/scalability/report/
# https://github.com/cilium/cilium/issues/23436
#   limits:
#     cpu: 4000m
#     memory: 4Gi
  requests:
    cpu: 50m
    memory: 512Mi

ipv4:
  enabled: true
ipv6:
  # enabling requires nodes to have ipv6 address
  enabled: false

# native or tunnel
routingMode: native
# geneve or vxlan
# vxlan doesn't support DSR
tunnelProtocol: geneve

# https://docs.cilium.io/en/latest/network/concepts/masquerading/
enableIPv4Masquerade: false
enableIPv6Masquerade: false
# when masquerading is enabled, ipv4NativeRoutingCIDR disables it for packets sent into specified cidr
# ipv4NativeRoutingCIDR: 10.201.0.0/16

# required when pod CIDR doesn't match node network CIDR
# autoDirectNodeRoutes: true
ipam:
  # mode: kubernetes
  mode: multi-pool
k8s:
  requireIPv4PodCIDR: false

endpointRoutes:
  # creates a /32 or /128 route for each pod
  # when this is disabled, a single route for node CIDR is created instead
  # required when using multi-pool ipam because in this case node doesn't have a static CIDR
  enabled: true

enableIPv4BIGTCP: true
enableIPv6BIGTCP: true

# automatic MTU detection seems to be working fine for me
# MTU: 1500
bpf:
  # use bpf masquerade instead of linux kernel masquerade
  # must be disabled when masquerade is not used
  masquerade: false
  # netkit requirements: Kernel >= 6.8, eBPF host-routing
  datapathMode: netkit
  lbExternalClusterIP: true
  # -- (float64) Configure auto-sizing for all BPF maps based on available memory.
  # ref: https://docs.cilium.io/en/stable/network/ebpf/maps/
  # @default -- `0.0025`
  mapDynamicSizeRatio: ~
  # allocate bpf maps per core instead of per-system
  # size of each map will decrease according to amount of cores
  # you can adjust mapDynamicSizeRatio if this is an issue
  distributedLRU:
    enabled: true
bpfClockProbe: true
installNoConntrackIptablesRules: true

encryption:
  # encryption is slow
  # https://github.com/cilium/cilium/issues/28413
  # also see test/iperf3 folder in this repo
  enabled: false
  type: wireguard

endpointLockdownOnMapOverflow: true

# Use "kubernetes.io/egress-bandwidth" pod annotation
bandwidthManager:
  enabled: true
  bbr: true

l2announcements:
  enabled: false
  # -- If a lease is not renewed for X duration, the current leader is considered dead, a new leader is picked
  leaseDuration: 15s
  # -- The interval at which the leader will renew the lease
  leaseRenewDeadline: 5s
  # -- The timeout between retries if renewal fails
  leaseRetryPeriod: 2s

# default values are 5/10 which is too small for the loadbalancer leader election
# QPS = #services * (1 / leaseRenewDeadline) + 10
k8sClientRateLimit:
  # default is 10
  qps: 100
  burst: 200

envoy:
  # by default envoy is running in the cilium agent pods
  # this options decouples it into separate pods
  enabled: true
  resources:
    requests:
      cpu: 5m
      memory: 20Mi
    limits:
      memory: 100Mi
l2podAnnouncements:
  # Gratuitous ARP only, you still need proxy_arp to allow connectivity
  enabled: true
  # interface: eth1
  interfacePattern: ^eth.*$
pmtuDiscovery:
  enabled: true
externalIPs:
  # when l2 announcements are enabled:
  # announce values from Service.spec.externalIPs
  enabled: true

loadBalancer:
  algorithm: maglev
  # mode=snat uses SNAT for services with `externalTrafficPolicy=Cluster`
  # mode=dsr disables SNAT (preserves client IP) but reduces MTU for UDP traffic
  # mode=hybrid disables SNAT for TCP but keeps it for UDP
  mode: dsr
  # opt, ipip, geneve, default opt
  dsrDispatch: opt
  acceleration: best-effort
  # -- experimental enables support for the experimental load-balancing
  # control-plane.
  experimental: true

gatewayAPI:
  # This will automatically set enable-envoy-config as well.
  enabled: true
  # -- SecretsNamespace is the namespace in which envoy SDS will retrieve TLS secrets from.
  secretsNamespace:
    create: false
    name: cilium-secrets
    # -- Enable secret sync, which will make sure all TLS secrets used by Ingress are synced to secretsNamespace.name.
    # If disabled, TLS secrets must be maintained externally.
    sync: false
  externalTrafficPolicy: Local

ingressController:
  enabled: false
  secretsNamespace:
    create: false
    name: cilium-secrets
    sync: false

envoyConfig:
  enabled: false
  secretsNamespace:
    create: false
    name: cilium-secrets
    sync: false

tls:
  secretsBackend: k8s
  secretsNamespace:
    create: false
    name: cilium-secrets
    sync: false
  secretSync:
    enabled: false

hubble:
  enabled: true
  relay:
    enabled: true
    resources:
      requests:
        cpu: 1m
        memory: 30Mi
      limits:
        memory: 50Mi
  ui:
    enabled: true
    backend:
      resources:
        requests:
          cpu: 1m
          memory: 15Mi
        limits:
          memory: 30Mi
    frontend:
      resources:
        requests:
          cpu: 1m
          memory: 5Mi
        limits:
          memory: 10Mi
  metrics:
    enableOpenMetrics: false
    # -- Configures the list of metrics to collect. If empty or null, metrics are disabled.
    # note that there is no way to count bytes transferred
    #     https://github.com/cilium/cilium/issues/16188
    enabled:
    # source_ip and destination_ip can sometimes be useful but they create cardinality explosion
    # flows-to-world:any-drop, flows-to-world:port cause cardinality explosion
    - dns:sourceContext=reserved-identity|pod;destinationContext=reserved-identity|pod;labelsContext=source_namespace,source_pod,destination_namespace,destination_pod,traffic_direction
    - drop:sourceContext=reserved-identity|pod;destinationContext=reserved-identity|pod;labelsContext=source_namespace,source_pod,destination_namespace,destination_pod,traffic_direction
    - flow:sourceContext=reserved-identity|pod;destinationContext=reserved-identity|pod;labelsContext=source_namespace,source_pod,destination_namespace,destination_pod,traffic_direction
    - flows-to-world:sourceContext=reserved-identity|pod;destinationContext=reserved-identity|pod;labelsContext=source_namespace,source_pod,destination_namespace,destination_pod,traffic_direction
    - icmp:sourceContext=reserved-identity|pod;destinationContext=reserved-identity|pod;labelsContext=source_namespace,source_pod,destination_namespace,destination_pod,traffic_direction
    # port-distribution creates cardinality explosion
    # - port-distribution:sourceContext=reserved-identity|pod;destinationContext=reserved-identity|pod;labelsContext=source_namespace,source_pod,destination_namespace,destination_pod,traffic_direction
    # tcp flags aren't very useful?
    # - tcp:sourceContext=reserved-identity|pod;destinationContext=reserved-identity|pod;labelsContext=source_namespace,source_pod,destination_namespace,destination_pod,traffic_direction
  tls:
    auto:
      enabled: true
      # renew certificates automatically
      # remove certificates from generated .gen.yaml file
      method: certmanager
      certManagerIssuerRef:
        group: cert-manager.io
        kind: ClusterIssuer
        name: cluster-ca
  # -- Emit v1.Events related to pods on detection of packet drops.
  #    This feature is alpha, please provide feedback at https://github.com/cilium/cilium/issues/33975.
  dropEventEmitter:
    enabled: true
    # --- Minimum time between emitting same events.
    interval: 2m
    # --- Drop reasons to emit events for.
    # ref: https://docs.cilium.io/en/stable/_api/v1/flow/README/#dropreason
    reasons:
    - auth_required
    - policy_denied

rollOutCiliumPods: true
operator:
  rollOutPods: true
  resources:
    requests:
      cpu: 5m
      memory: 64Mi
    limits:
      memory: 128Mi
  # tolerations: []
    # - operator: Exists
      # - key: "key"
      #   operator: "Equal|Exists"
      #   value: "value"
      #   effect: "NoSchedule|PreferNoSchedule|NoExecute(1.6 only)"
# -- Cilium agent update strategy
updateStrategy:
  type: RollingUpdate
  rollingUpdate:
    maxUnavailable: 100%
